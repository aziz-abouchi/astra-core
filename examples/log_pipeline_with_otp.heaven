-- examples/02-data-pipelines/log_pipeline_with_otp.heaven
-- Pipeline avec GenServer pour l'état et Supervisor pour la résilience
-- Intégration OTP behaviors + Pony capabilities

module LogPipeline

import OTP.GenServer
import OTP.Supervisor
import OTP.Application
import Data.Stream
import Data.Window
import Logic.MiniKanren

-- Types de logs
data LogLevel = Debug | Info | Warning | Error | Critical

record LogEntry where
  constructor MkLogEntry
  timestamp : Time
  level : LogLevel
  service : String
  message : String
  metadata : List (String, String)

-- Messages GenServer pour le processeur de logs
data ProcessorCall
  = GetStatistics
  | GetThroughput

data ProcessorCast
  = ProcessLog LogEntry
  | UpdateConfig PipelineConfig

data ProcessorInfo
  = FlushBuffer
  | ComputeMetrics

-- État du GenServer
record ProcessorState where
  constructor MkProcessorState
  buffer : List LogEntry
  bufferSize : Nat
  stats : LogStatistics
  config : PipelineConfig

record PipelineConfig where
  constructor MkPipelineConfig
  batchSize : Nat
  flushInterval : Duration
  parallelism : Nat

record LogStatistics where
  constructor MkLogStats
  totalProcessed : Nat
  errorCount : Nat
  throughputPerSec : Double
  lastFlush : Time

-- GenServer behavior pour le processeur de logs
behavior LogProcessor : GenServer ProcessorCall ProcessorCast ProcessorInfo ProcessorState where
  init : PipelineConfig -> Effect (InitResult ProcessorState)
  init config = do
    logInfo "Démarrage LogProcessor, batch size: \{show config.batchSize}"
    schedule FlushBuffer config.flushInterval
    schedule ComputeMetrics (seconds 10)
    now <- currentTime
    pure $ InitOk (MkProcessorState [] Z (MkLogStats Z Z 0.0 now) config)
  
  -- Calls synchrones
  handleCall : ProcessorCall -> From -> ProcessorState -> Effect (CallResult ProcessorState)
  handleCall GetStatistics from state =
    pure $ Reply state.stats state
  
  handleCall GetThroughput from state =
    pure $ Reply state.stats.throughputPerSec state
  
  -- Casts asynchrones
  handleCast : ProcessorCast -> ProcessorState -> Effect (CastResult ProcessorState)
  handleCast (ProcessLog entry) state = do
    let newBuffer = entry :: state.buffer
    let newSize = S state.bufferSize
    
    -- Flush si buffer plein
    if newSize >= state.config.batchSize
      then do
        processBatch newBuffer state.config
        let newStats = updateStats (length newBuffer) state.stats
        pure $ NoReply (record { buffer = []
                               , bufferSize = Z
                               , stats = newStats } state)
      else
        pure $ NoReply (record { buffer = newBuffer
                               , bufferSize = newSize } state)
  
  handleCast (UpdateConfig newConfig) state = do
    logInfo "Configuration mise à jour"
    pure $ NoReply (record { config = newConfig } state)
  
  -- Messages info (timers)
  handleInfo : ProcessorInfo -> ProcessorState -> Effect (InfoResult ProcessorState)
  handleInfo FlushBuffer state = do
    when (state.bufferSize > Z) $ do
      processBatch state.buffer state.config
      let newStats = updateStats (length state.buffer) state.stats
      GenServer.cast metricsCollector (UpdateMetrics newStats)
    
    -- Re-schedule
    schedule FlushBuffer state.config.flushInterval
    pure $ NoReply (record { buffer = [], bufferSize = Z } state)
  
  handleInfo ComputeMetrics state = do
    now <- currentTime
    let elapsed = diffTime now state.stats.lastFlush
    let throughput = cast state.stats.totalProcessed / toSeconds elapsed
    let newStats = record { throughputPerSec = throughput } state.stats
    
    schedule ComputeMetrics (seconds 10)
    pure $ NoReply (record { stats = newStats } state)
  
  terminate : Reason -> ProcessorState -> Effect ()
  terminate reason state = do
    -- Flush final du buffer
    when (state.bufferSize > Z) $
      processBatch state.buffer state.config
    logInfo "LogProcessor terminé: \{show reason}"

-- GenServer pour la détection de patterns (avec miniKanren)
data PatternCall
  = GetDetectedPatterns

data PatternCast
  = AnalyzeSequence (List LogEntry)

record PatternState where
  constructor MkPatternState
  patterns : List Pattern
  analysisWindow : List LogEntry
  windowSize : Nat

data Pattern
  = RepeatedErrors String Nat
  | SuspiciousSequence (List LogEntry)
  | AnomalousRate String Double

behavior PatternDetector : GenServer PatternCall PatternCast () PatternState 
  with logicCapability : val  -- Pony capability pour logique pure
  where
  init : Nat -> Effect (InitResult PatternState)
  init windowSize = do
    logInfo "Démarrage PatternDetector, window: \{show windowSize}"
    pure $ InitOk (MkPatternState [] [] windowSize)
  
  handleCall : PatternCall -> From -> PatternState -> Effect (CallResult PatternState)
  handleCall GetDetectedPatterns from state =
    pure $ Reply state.patterns state
  
  handleCast : PatternCast -> PatternState -> Effect (CastResult PatternState)
  handleCast (AnalyzeSequence logs) state = do
    let newWindow = take state.windowSize (logs ++ state.analysisWindow)
    
    -- Détection avec miniKanren (logique relationnelle)
    let detected = detectPatterns newWindow
    let significant = filter ((> 0.8) . confidence) detected
    
    -- Notification des patterns trouvés
    traverse_ (\p => GenServer.cast alertService (PatternAlert p)) significant
    
    pure $ NoReply (record { patterns = significant ++ state.patterns
                           , analysisWindow = newWindow } state)

-- GenServer pour les métriques (avec Pony behavior)
data MetricsCall
  = GetAllMetrics
  | GetServiceMetrics String

data MetricsCast
  = UpdateMetrics LogStatistics
  | RecordMetric String Nat

record MetricsState where
  constructor MkMetricsState
  globalStats : LogStatistics
  byService : Map String ServiceMetrics
  history : List (Time, LogStatistics)

behavior MetricsCollector : GenServer MetricsCall MetricsCast () MetricsState
  with metricsCapability : ref  -- Pony capability mutable partagée
  where
  init : () -> Effect (InitResult MetricsState)
  init () = do
    now <- currentTime
    let initialStats = MkLogStats Z Z 0.0 now
    pure $ InitOk (MkMetricsState initialStats empty [])
  
  handleCall : MetricsCall -> From -> MetricsState -> Effect (CallResult MetricsState)
  handleCall GetAllMetrics from state =
    pure $ Reply (buildMetricsReport state) state
  
  handleCall (GetServiceMetrics service) from state =
    case lookup service state.byService of
      Just metrics => pure $ Reply metrics state
      Nothing => pure $ Reply emptyMetrics state
  
  handleCast : MetricsCast -> MetricsState -> Effect (CastResult MetricsState)
  handleCast (UpdateMetrics stats) state = do
    now <- currentTime
    let newHistory = take 1000 ((now, stats) :: state.history)
    pure $ NoReply (record { globalStats = stats
                           , history = newHistory } state)
  
  handleCast (RecordMetric service count) state = do
    let current = lookupOr emptyServiceMetrics service state.byService
    let updated = incrementServiceMetric current count
    let newByService = insert service updated state.byService
    pure $ NoReply (record { byService = newByService } state)

-- Supervisor avec stratégie rest_for_one (si un worker crash, restart lui et suivants)
pipelineSupervisor : SupervisorSpec
pipelineSupervisor = MkSupervisor
  { strategy = RestForOne  -- Restart cascade
  , intensity = 5
  , period = seconds 60
  , children =
      [ -- Worker 1: Processeur principal
        worker "log_processor"
          (startLink LogProcessor defaultConfig)
          Permanent
          (seconds 5)
      
      , -- Worker 2: Détecteur de patterns (dépend du processeur)
        worker "pattern_detector"
          (startLink PatternDetector 100)
          Permanent
          (seconds 5)
      
      , -- Worker 3: Collecteur de métriques
        worker "metrics_collector"
          (startLink MetricsCollector ())
          Permanent
          (seconds 5)
      ]
  }

-- Supervisor pour plusieurs instances de processeurs (pool pattern)
processorPoolSupervisor : Nat -> SupervisorSpec
processorPoolSupervisor poolSize = MkSupervisor
  { strategy = OneForOne
  , intensity = 10
  , period = seconds 60
  , children = map makeWorker [1..poolSize]
  }
  where
    makeWorker : Nat -> ChildSpec
    makeWorker n = 
      worker "log_processor_\{show n}"
        (startLink LogProcessor defaultConfig)
        Permanent
        (seconds 5)

-- Application behavior principale
behavior LogPipelineApp : Application where
  start : StartType -> List String -> Effect (Either Error Pid)
  start startType args = do
    logInfo "Démarrage Log Pipeline Application"
    
    -- Parser les arguments
    let poolSize = parsePoolSize args `orElse` 4
    
    -- Démarrer le supervisor principal
    result <- Supervisor.startLink pipelineSupervisor
    
    case result of
      Right supPid => do
        -- Enregistrer les services
        register "log_processor" =<< whereis "log_processor"
        register "pattern_detector" =<< whereis "pattern_detector"
        register "metrics_collector" =<< whereis "metrics_collector"
        
        -- Démarrer le pool de processeurs
        poolSupPid <- Supervisor.startLink (processorPoolSupervisor poolSize)
        register "processor_pool_sup" poolSupPid
        
        -- Distribution
        distributeServices poolSize
        
        -- Connecter à la source de logs
        connectLogSource
        
        logInfo "Pipeline opérationnel avec \{show poolSize} workers"
        pure $ Right supPid
      
      Left err => do
        logError "Échec: \{show err}"
        pure $ Left err
  
  stop : AppState -> Effect ()
  stop state = do
    logInfo "Arrêt Log Pipeline Application"
    disconnectLogSource

-- Distribution des services sur le cluster
distributeServices : Nat -> Effect ()
distributeServices poolSize = do
  -- Distribuer les processeurs sur plusieurs nœuds
  forM_ [1..poolSize] $ \n => do
    pid <- whereis "log_processor_\{show n}"
    let node = "processing-\{show $ n `mod` 3}@cluster"
    distributeProcess pid node
  
  -- Détecteur sur nœud ML
  patternPid <- whereis "pattern_detector"
  distributeProcess patternPid "ml-node@cluster"
  
  -- Métriques sur nœud analytics
  metricsPid <- whereis "metrics_collector"
  distributeProcess metricsPid "analytics-node@cluster"

-- Connexion à la source de logs (Kafka, etc.)
connectLogSource : Effect ()
connectLogSource = do
  -- Source Kafka
  source <- connectKafka "application-logs"
  
  -- Consumer group
  spawn $ kafkaConsumer source $ \entry => do
    -- Load balancing round-robin vers le pool
    pid <- selectProcessor
    GenServer.cast pid (ProcessLog entry)

-- Sélection d'un processeur du pool (round-robin)
selectProcessor : Effect Pid
selectProcessor = do
  poolSize <- getPoolSize
  counter <- getAndIncrementCounter
  let index = counter `mod` poolSize
  whereis "log_processor_\{show (index + 1)}"

-- Helper functions
processBatch : List LogEntry -> PipelineConfig -> Effect ()
processBatch logs config = do
  -- Traitement parallèle avec parMap
  let results = parMap (processEntry config) logs
  
  -- Envoi vers destinations
  traverse_ sendToDestination results
  
  -- Analyse de patterns
  patternPid <- whereis "pattern_detector"
  GenServer.cast patternPid (AnalyzeSequence logs)

processEntry : PipelineConfig -> LogEntry -> ProcessedLog
processEntry config entry =
  enrichWithContext entry
  |> validateEntry
  |> detectAnomalies

updateStats : Nat -> LogStatistics -> LogStatistics
updateStats count stats =
  record { totalProcessed = stats.totalProcessed + count
         , errorCount = stats.errorCount + countErrors logs } stats

defaultConfig : PipelineConfig
defaultConfig = MkPipelineConfig 100 (seconds 5) 4

-- Point d'entrée
main : IO ()
main = do
  args <- getArgs
  
  result <- Application.start LogPipelineApp Normal args
  
  case result of
    Right supPid => do
      putStrLn "✓ Log Pipeline System démarré"
      putStrLn "  Supervisor: \{show supPid}"
      putStrLn "  Distribution: processing-*@cluster"
      putStrLn "  Métriques: :9090/metrics"
      
      -- Exposition Prometheus
      spawn $ serveMetrics 9090
      
      receive
    
    Left err => do
      putStrLn "✗ Échec: \{show err}"
      exitWith 1
